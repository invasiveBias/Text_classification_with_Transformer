{"cells":[{"cell_type":"markdown","id":"e025030b","metadata":{"id":"e025030b"},"source":["This is a project to build a Transformer model that performs sentiment analysis on data made up of text sentences. The aim is to predict whether the sentiment behind the texts is positive or negative."]},{"cell_type":"markdown","id":"51650da8","metadata":{"id":"51650da8"},"source":["# About Transformers\n","Transformers are deep learning models used for processing sequential data, but they are far more powerful and can handle longer sequences than RNNs & member models(LSTMs & GRUs) without the gradient vanishing or exploding problem, this is because unlike RNNs that process data at one point in time with respect to data at the previous point, transformers tend to analyse data at particular with respect to all points in the sequence both previous & forward(ie in a sentence it would find the importance of each word with respect to other words both before & after it)<br>\n","Transformers are most times used for sequence to sequence predictions so they would have an Encoder & Decoder parts,During training the vectorised word sequences are passed through an embedding layer which contains 2 stages,the normal input embedding that converts the vectorised words into embedding vectors which is the standard for Natural language processing wuth deep learning and then a positional embedding to mark the position of each word in the sequence so as to reveal context(ie how the position of the word would affect the entire sentence) this is then moved to the decoder in which the model tries to find the importance of each word in the input sequence relative to other words in the sequence(this process is known as Attention), moving to the Encoder,the model initially uses a twikked form of the attention method to find the importance of each word in the output sequence relative to other words that came before it in the sequence,meaning that it will block words in the future/later part of the sequence(this method is called \"Masking/Masked Attention\" & it's done so that during inference/testing the model doesn't expect any future word in the output & hence would predict output words on it's own), it then takes the results of this operation & uses the normal attention method to find the importance of each word in the input sequence(already processed in the Decoder) relative to each the each word in the output sequence(which has been initially processed by Encoder), with this it can be able to establish the relationship between words in the input & output sequences simultaenously.<br>\n","But since we're doing simple text classificaton in this project, we would be using only the embedding layer & the decoder part of the Transformer which would then be given to a dense layer(s),this is just to simply learn the relationship between words in the input sequences relative to their respective classes.\n","The model architecture for this project is divided into 4 parts\n","1. **The Embeddings layers :**  containing the standard & positonal embedding layers & the feeds into the next layer\n","2. **The Multi-headed attention layer :** this is part where the attention is peformed after taking the embedded sequences, the layer contains more than one attention head in other to give diversity to how the model analyses each word relative to the other words in the input sequence,the results from the different attention layers are then normalised/averaged & the final result is added to the original embbeding input\n","3. **The feed forward layer :** this takes the processed sequence from the attention layer through a normal feed forward network that usually has a Relu activation function\n","4. **The final dense layer :** this is the final dense layer that takes the sequences from the previous feed-forward layer for final classifcation,it would have either a sigmoid or softmax activation function."]},{"cell_type":"code","execution_count":null,"id":"8bda9716","metadata":{"id":"8bda9716"},"outputs":[],"source":["import pandas as pd, numpy as np # import necessary libraries"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GcKpybsDbSYa","executionInfo":{"status":"ok","timestamp":1679420160944,"user_tz":-60,"elapsed":47089,"user":{"displayName":"Uchechukwu Otakpor","userId":"02521081653992439802"}},"outputId":"3fbfffa0-4603-4cd6-ca57-51c341fc3758"},"id":"GcKpybsDbSYa","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"id":"d19afc8c","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"id":"d19afc8c","executionInfo":{"status":"ok","timestamp":1679420196514,"user_tz":-60,"elapsed":8299,"user":{"displayName":"Uchechukwu Otakpor","userId":"02521081653992439802"}},"outputId":"f6b57a93-b637-416a-e513-5bbbb34d5fba"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 Unnamed: 0  \\\n","110262               259810   \n","595029                85357   \n","48944   2022-03-09 14:03:47   \n","371353              1507730   \n","110056               106578   \n","\n","                                                     text  overall  \n","110262  After several months of use we're looking for ...        0  \n","595029  Need to contact Megan. Megan not replying. No ...        0  \n","48944   The app is good, but I can't play my liked son...        2  \n","371353  I think Defender would have been better, I've ...        1  \n","110056  Cheap and flimsy, Served the purpose, but I ca...        2  "],"text/html":["\n","  <div id=\"df-c4ca451a-6192-40ff-95a7-47faa4fb22cf\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>text</th>\n","      <th>overall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>110262</th>\n","      <td>259810</td>\n","      <td>After several months of use we're looking for ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>595029</th>\n","      <td>85357</td>\n","      <td>Need to contact Megan. Megan not replying. No ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>48944</th>\n","      <td>2022-03-09 14:03:47</td>\n","      <td>The app is good, but I can't play my liked son...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>371353</th>\n","      <td>1507730</td>\n","      <td>I think Defender would have been better, I've ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>110056</th>\n","      <td>106578</td>\n","      <td>Cheap and flimsy, Served the purpose, but I ca...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4ca451a-6192-40ff-95a7-47faa4fb22cf')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c4ca451a-6192-40ff-95a7-47faa4fb22cf button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c4ca451a-6192-40ff-95a7-47faa4fb22cf');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["# load the data (this data was made from 1.6million tweets tat were classified as either positive or negative)\n","data = pd.read_csv('drive/MyDrive/Portfolio resources/Sentiment analysis & explication dataset/product_review.csv')\n","data = data.dropna()\n","data = data.sample(frac=1)\n","data.head()"]},{"cell_type":"code","execution_count":null,"id":"c38fc53d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c38fc53d","executionInfo":{"status":"ok","timestamp":1679420205715,"user_tz":-60,"elapsed":18,"user":{"displayName":"Uchechukwu Otakpor","userId":"02521081653992439802"}},"outputId":"e146b6ec-cc5e-4c82-ea60-f658fa237b32"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    200000\n","2    199999\n","1    199999\n","Name: overall, dtype: int64"]},"metadata":{},"execution_count":5}],"source":["data['overall'].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"9d56c073","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9d56c073","executionInfo":{"status":"ok","timestamp":1679420218929,"user_tz":-60,"elapsed":473,"user":{"displayName":"Uchechukwu Otakpor","userId":"02521081653992439802"}},"outputId":"105d5fc8-cafd-4190-a4d9-53fadc7820d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 599998 entries, 110262 to 575494\n","Data columns (total 3 columns):\n"," #   Column      Non-Null Count   Dtype \n","---  ------      --------------   ----- \n"," 0   Unnamed: 0  599998 non-null  object\n"," 1   text        599998 non-null  object\n"," 2   overall     599998 non-null  int64 \n","dtypes: int64(1), object(2)\n","memory usage: 18.3+ MB\n"]}],"source":["data.info() # data info"]},{"cell_type":"code","execution_count":null,"id":"4ba6ad36","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"4ba6ad36","executionInfo":{"status":"ok","timestamp":1679420220742,"user_tz":-60,"elapsed":18,"user":{"displayName":"Uchechukwu Otakpor","userId":"02521081653992439802"}},"outputId":"35797841-481c-429b-cba4-6ea45d0019e3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["             overall\n","count  599998.000000\n","mean        0.999998\n","std         0.816498\n","min         0.000000\n","25%         0.000000\n","50%         1.000000\n","75%         2.000000\n","max         2.000000"],"text/html":["\n","  <div id=\"df-0b259157-b793-4a2b-8f0b-8b38c9cdcfa5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>overall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>599998.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.999998</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.816498</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>2.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>2.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b259157-b793-4a2b-8f0b-8b38c9cdcfa5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0b259157-b793-4a2b-8f0b-8b38c9cdcfa5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0b259157-b793-4a2b-8f0b-8b38c9cdcfa5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}],"source":["data.describe() # describe data"]},{"cell_type":"code","execution_count":null,"id":"912d1e68","metadata":{"id":"912d1e68"},"outputs":[],"source":["# import libraries for model development\n","import tensorflow as tf,keras\n","from sklearn.model_selection import train_test_split\n","from keras import layers\n","from keras.callbacks import ModelCheckpoint\n","from keras.layers import TextVectorization"]},{"cell_type":"code","source":["import string\n","stg = string.punctuation.replace(\"'\",'')\n","def custom_standardization(input_string):\n","    lowercased = tf.strings.lower(input_string)\n","    stripped_html = tf.strings.regex_replace(lowercased, \"\\n\", \" \")\n","    return tf.strings.regex_replace(stripped_html, f\"([{stg}])\", r\"\")"],"metadata":{"id":"p95CeetKV3kn"},"id":"p95CeetKV3kn","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"d9440549","metadata":{"id":"d9440549"},"outputs":[],"source":["import pickle\n","from_disk = pickle.load(open(\"drive/MyDrive/Portfolio resources/product_rev_vectorizer_weights\", \"rb\"))\n","#del from_disk['config']['encoding']\n","new_v = TextVectorization.from_config(from_disk['config'])\n","new_v.set_weights(from_disk['weights'])"]},{"cell_type":"code","source":["X = new_v(data['text'])\n","y = data['overall']\n","X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y, test_size=0.1, random_state=42)"],"metadata":{"id":"x5eG4QstWRqY"},"id":"x5eG4QstWRqY","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"89dc726f","metadata":{"id":"89dc726f"},"outputs":[],"source":["# creating the Embedding layer\n","class TokenAndPositionEmbedding(layers.Layer):\n","    def __init__(self, maxlen, vocab_size, embed_dim,**kwargs):\n","        super().__init__(**kwargs)\n","        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim) # standard embedding layer\n","        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim) # another standard embedding layer(to be later used for positional embedding)\n","\n","    def call(self, x):\n","        maxlen = tf.shape(x)[-1] # getting the sequence length\n","        positions = tf.range(start=0, limit=maxlen, delta=1) # using the sequence length to create empty vectors for positional embedding\n","        positions = self.pos_emb(positions)# merging the positonal vectors with the2nd standard embeeding to create the positional embedding layer\n","        x = self.token_emb(x) # putting the vectorised sequences in the 1st embedding layer for standard embedding\n","        return x + positions # returning the sum of the standard & positional embddings\n"]},{"cell_type":"code","execution_count":null,"id":"dcac2c48","metadata":{"id":"dcac2c48"},"outputs":[],"source":["# creating the transformer layer\n","class TransformerBlock(layers.Layer):\n","    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1,**kwargs):\n","        super().__init__(**kwargs)\n","        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim) # multi-head attention layer\n","        self.ffn = keras.Sequential(\n","            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n","        )# feed forward layer\n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)# first normalisaton layer to normalise the sum of the multi-head attention layer with the embbding layer output\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6) # 2nd normalisaton layer to normalise the sum of the feed forward layer with the multi-head attention output\n","        self.dropout1 = layers.Dropout(rate) # dropout layer1\n","        self.dropout2 = layers.Dropout(rate) # dropout layer2\n","\n","    def call(self, inputs, training):\n","        attn_output = self.att(inputs, inputs) # giving the attention layer the inputs to use for the queries & keys (if not given the layer would use whatever is given as the key for the key-values) to perform attention\n","        attn_output = self.dropout1(attn_output, training=training)  # putting the result of the attention layer within a dropout layer to reduce overfitiing(training is set to itself to indicate true)\n","        out1 = self.layernorm1(inputs + attn_output) # adding the results of the attention layer with its inputs(the embedded layer result) & then normalising it\n","        ffn_output = self.ffn(out1) # giving the product of the normalisation to the feed forward layer\n","        ffn_output = self.dropout2(ffn_output, training=training) # putting the result of the feed forward layer within a dropout layer to reduce overfitiing(training is set to itself to indicate true)\n","        return self.layernorm2(out1 + ffn_output) # adding the results of the feed forward layer with its inputs(the attention layer result) & then normalising it\n"]},{"cell_type":"code","execution_count":null,"id":"395bccdf","metadata":{"id":"395bccdf"},"outputs":[],"source":["# building the entire model\n","embed_dim = 32  # Embedding size for each token\n","num_heads = 3  # Number of attention heads\n","ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n","maxlen=101\n","vocab_size=25000\n","inputs = layers.Input(shape=(maxlen,)) # input for vectorised model\n","embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n","x = embedding_layer(inputs)\n","transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n","x = transformer_block(x)\n","x = layers.GlobalAveragePooling1D()(x) # pooling the result of the feed forward layer\n","x = layers.Dropout(0.1)(x)\n","x = layers.Dense(20, activation=\"relu\")(x) # additional dense layer\n","x = layers.Dropout(0.1)(x)\n","outputs = layers.Dense(3, activation=\"softmax\")(x) # final dense layer\n","model = keras.Model(inputs=inputs, outputs=outputs)"]},{"cell_type":"code","execution_count":null,"id":"ebf93a1c","metadata":{"id":"ebf93a1c"},"outputs":[],"source":["# creating a model checkpoint callback\n","filepath=\"drive/MyDrive/Collab Models/review_sent_model.hdf5\"\n","checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n","callbacks_list = [checkpoint]"]},{"cell_type":"code","execution_count":null,"id":"9144f729","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9144f729","executionInfo":{"status":"ok","timestamp":1679423802628,"user_tz":-60,"elapsed":2500319,"user":{"displayName":"Uchechukwu Otakpor","userId":"02521081653992439802"}},"outputId":"0ab38ad8-6311-4939-f418-8a485e838a5d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1055/1055 [==============================] - ETA: 0s - loss: 0.6960 - accuracy: 0.6956\n","Epoch 1: val_loss improved from inf to 0.62220, saving model to drive/MyDrive/Collab Models/review_sent_model.hdf5\n","1055/1055 [==============================] - 699s 660ms/step - loss: 0.6960 - accuracy: 0.6956 - val_loss: 0.6222 - val_accuracy: 0.7311\n","Epoch 2/5\n","1055/1055 [==============================] - ETA: 0s - loss: 0.6076 - accuracy: 0.7429\n","Epoch 2: val_loss did not improve from 0.62220\n","\n","Epoch 2: val_loss did not improve from 0.62220\n","1055/1055 [==============================] - 708s 671ms/step - loss: 0.6076 - accuracy: 0.7429 - val_loss: 0.6311 - val_accuracy: 0.7308\n","1055/1055 [==============================] - 708s 671ms/step - loss: 0.6076 - accuracy: 0.7429 - val_loss: 0.6311 - val_accuracy: 0.7308\n","Epoch 3/5\n","Epoch 3/5\n","1055/1055 [==============================] - ETA: 0s - loss: 0.5834 - accuracy: 0.7533\n","Epoch 3: val_loss improved from 0.62220 to 0.61038, saving model to drive/MyDrive/Collab Models/review_sent_model.hdf5\n","\n","Epoch 3: val_loss improved from 0.62220 to 0.61038, saving model to drive/MyDrive/Collab Models/review_sent_model.hdf5\n","1055/1055 [==============================] - 721s 683ms/step - loss: 0.5834 - accuracy: 0.7533 - val_loss: 0.6104 - val_accuracy: 0.7374\n","1055/1055 [==============================] - 721s 683ms/step - loss: 0.5834 - accuracy: 0.7533 - val_loss: 0.6104 - val_accuracy: 0.7374\n","Epoch 4/5\n","Epoch 4/5\n","1055/1055 [==============================] - ETA: 0s - loss: 0.5637 - accuracy: 0.7616\n","Epoch 4: val_loss did not improve from 0.61038\n","\n","Epoch 4: val_loss did not improve from 0.61038\n","1055/1055 [==============================] - 711s 674ms/step - loss: 0.5637 - accuracy: 0.7616 - val_loss: 0.6146 - val_accuracy: 0.7352\n","1055/1055 [==============================] - 711s 674ms/step - loss: 0.5637 - accuracy: 0.7616 - val_loss: 0.6146 - val_accuracy: 0.7352\n","Epoch 5/5\n","Epoch 5/5\n","1055/1055 [==============================] - ETA: 0s - loss: 0.5448 - accuracy: 0.7679\n","Epoch 5: val_loss did not improve from 0.61038\n","\n","Epoch 5: val_loss did not improve from 0.61038\n","1055/1055 [==============================] - 708s 671ms/step - loss: 0.5448 - accuracy: 0.7679 - val_loss: 0.6220 - val_accuracy: 0.7376\n","1055/1055 [==============================] - 708s 671ms/step - loss: 0.5448 - accuracy: 0.7679 - val_loss: 0.6220 - val_accuracy: 0.7376\n"]}],"source":["# training the model\n","model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n","history = model.fit(\n","    X_train, y_train, batch_size=512, epochs=5, validation_data=(X_test, y_test),callbacks=callbacks_list)"]},{"cell_type":"code","execution_count":null,"id":"d52d4427","metadata":{"id":"d52d4427"},"outputs":[],"source":["# creating function for model prediction\n","def predict(dt,mdl):\n","    try:\n","        x = new_v(dt['text'].values)\n","        pred = mdl.predict(x)\n","    except Exception as err:\n","        pred = mdl.predict(dt)\n","    return pred"]},{"cell_type":"code","execution_count":null,"id":"f5cc08cb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f5cc08cb","executionInfo":{"status":"ok","timestamp":1679423843326,"user_tz":-60,"elapsed":40707,"user":{"displayName":"Uchechukwu Otakpor","userId":"02521081653992439802"}},"outputId":"e28165db-4c97-4fff-bcb9-7adcc60ccd76"},"outputs":[{"output_type":"stream","name":"stdout","text":["1875/1875 [==============================] - 34s 18ms/step\n","1875/1875 [==============================] - 34s 18ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([0, 2, 2, ..., 0, 2, 1])"]},"metadata":{},"execution_count":18},{"output_type":"execute_result","data":{"text/plain":["array([0, 2, 2, ..., 0, 2, 1])"]},"metadata":{},"execution_count":18}],"source":["# predicting text values\n","pred = predict(X_test,model)\n","pred = np.argmax(pred,axis=1)\n","pred"]},{"cell_type":"code","execution_count":null,"id":"efce40ae","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"efce40ae","executionInfo":{"status":"ok","timestamp":1679423947334,"user_tz":-60,"elapsed":583,"user":{"displayName":"Uchechukwu Otakpor","userId":"02521081653992439802"}},"outputId":"30720e24-ace9-4d0d-e01f-6e04baf919f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.82      0.70      0.75     23507\n","           1       0.78      0.84      0.81     18703\n","           2       0.61      0.68      0.64     17790\n","\n","    accuracy                           0.74     60000\n","   macro avg       0.74      0.74      0.74     60000\n","weighted avg       0.75      0.74      0.74     60000\n","\n"]}],"source":["# show prediction metric\n","from sklearn.metrics import classification_report\n","print(classification_report(pred,y_test))"]},{"cell_type":"code","execution_count":null,"id":"fb9250b3","metadata":{"id":"fb9250b3","executionInfo":{"status":"ok","timestamp":1687874849263,"user_tz":-60,"elapsed":10,"user":{"displayName":"Uchechukwu Otakpor","userId":"02521081653992439802"}}},"outputs":[],"source":[]},{"cell_type":"code","source":[],"metadata":{"id":"cfT4U-4nu-cO"},"id":"cfT4U-4nu-cO","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}